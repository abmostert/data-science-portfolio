{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf246720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot matplotlib plots directly within a notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target & basic feature selection (avoid leakage columns like 'alive')\n",
    "target = \"survived\"\n",
    "features = [\"pclass\",\"sex\",\"age\",\"sibsp\",\"parch\",\"fare\",\"embarked\",\"alone\"]\n",
    "\n",
    "df = df[features + [target]].dropna(subset=[target])  # ensure target present\n",
    "X = df[features]\n",
    "y = df[target].astype(int)  # ensure binary 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6499195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols),\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__max_depth\": [3, 5, 7, 9, None],\n",
    "    \"clf__min_samples_split\": [2, 5, 10, 20],\n",
    "    \"clf__min_samples_leaf\": [1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=tree,\n",
    "    param_grid=param_grid,\n",
    "    scoring={\"acc\": \"accuracy\", \"f1\": \"f1\"},\n",
    "    refit=\"f1\",                  # pick best by F1 (more informative than accuracy here)\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "best_tree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8554ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=None, random_state=42, n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    yhat_tr = model.predict(X_tr)\n",
    "    yhat_te = model.predict(X_te)\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Acc (train)\": accuracy_score(y_tr, yhat_tr),\n",
    "        \"F1  (train)\": f1_score(y_tr, yhat_tr),\n",
    "        \"Acc (test)\":  accuracy_score(y_te, yhat_te),\n",
    "        \"F1  (test)\":  f1_score(y_te, yhat_te),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "rows.append(eval_model(\"DecisionTree (best)\", best_tree, X_train, y_train, X_test, y_test))\n",
    "rows.append(eval_model(\"RandomForest (300)\", rf, X_train, y_train, X_test, y_test))\n",
    "metrics_df = pd.DataFrame(rows).set_index(\"Model\")\n",
    "metrics_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902cc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "prep = best_tree.named_steps[\"prep\"]\n",
    "ohe = prep.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "num_names = num_cols\n",
    "cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "all_feature_names = num_names + cat_names\n",
    "\n",
    "# Extract importances from the final tree step\n",
    "clf = best_tree.named_steps[\"clf\"]\n",
    "importances = pd.Series(clf.feature_importances_, index=all_feature_names)\n",
    "imp_sorted = importances.sort_values(ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "imp_sorted.plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Decision Tree Feature Importances (top 15)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
